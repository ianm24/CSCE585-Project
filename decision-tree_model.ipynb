{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_folder = \"./data/\"\n",
    "\n",
    "#Get and load data\n",
    "# pitch_14_17_file = \"pitcher_2014_2017.csv\"\n",
    "bball_data_2_file = \"Baseball Data-2.csv\"\n",
    "\n",
    "TRAINING_FEATURES = ['RunsScored', 'VertBreak', 'HorzBreak', 'ZoneSpeed',\n",
    "       'VertApprAngle', 'HorzApprAngle', 'ZoneTime', 'BallStrikeNum', 'Zone']\n",
    "       \n",
    "LABELS_FEATURE = ['GroundTruth']\n",
    "PREPROCESSING_KEYS = ['Balls', 'Strikes', 'PitchCall', 'PlateLocHeight', 'PlateLocSide']\n",
    "\n",
    "SUBCATEGORY_KEYS = ['Pitcher', 'Batter', 'PitcherThrows', 'BatterSide', 'TaggedPitchType']\n",
    "TaggedPitchType_Keys = ['Fastball', 'Curveball', 'ChangeUp', 'Slider']\n",
    "PitcherThrows_Keys = ['Left', 'Right']\n",
    "BatterSide_Keys = ['Left', 'Right']\n",
    "\n",
    "PCT_FOR_TRAIN = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing function which moves 0 of PlateLocHeight to center of strike zone from ground\n",
    "#returns a value 2.5ft (30in) less than the original value\n",
    "def normalize_PlateLocHeight(PlateLocHeight):\n",
    "    return ((PlateLocHeight * 12) - 30)/12\n",
    "\n",
    "\n",
    "#preprocessing function used to calculate the plate location (this will be different than PitchCall (even in terms of BallCalled vs StrikeCalled))\n",
    "#returns classification: heart (strike) = 0, shadow (strike) = 1, shadow (ball) = 2, chase (ball) = 3, waste (ball) = 4\n",
    "def PlateZone(PlateLocHeight, PlateLocSide):\n",
    "    FOOT = 12\n",
    "\n",
    "    #waste zone\n",
    "    #outside 84in to 6in, -20in to 20in horizontal, (strike zone * 200%)\n",
    "    if ((PlateLocHeight > 7 or PlateLocHeight < 0.5) and (PlateLocSide < -(20/FOOT) or PlateLocSide > (20/FOOT))):\n",
    "        return 4\n",
    "\n",
    "    #heart zone\n",
    "    #inside 38in to 22in vertical, -6.7in to 6.7in horizontal, (strike zone size * 67%)\n",
    "    if ((PlateLocHeight < (38/FOOT) and PlateLocHeight > (22/FOOT)) and (PlateLocSide > (-6.7/FOOT) and PlateLocSide < (6.7/FOOT))):\n",
    "        return 0\n",
    "\n",
    "    #strike zone \n",
    "    #inside 42in to 18in vertical, -10in to 10in horizontal\n",
    "    if (PlateLocHeight < (42/FOOT) and PlateLocHeight > (18/FOOT) and (PlateLocSide > (-10/FOOT) and PlateLocSide < (10/FOOT))):\n",
    "        return 1\n",
    "\n",
    "    #shadow zone\n",
    "    #inside 46in to 14in vertical, -13.3in to 13.3in horizontal, (strike zone size * 133%)\n",
    "    if (PlateLocHeight < (46/FOOT) and PlateLocHeight > (14/FOOT) and (PlateLocSide > (-13.3/FOOT) and PlateLocSide < (13.3/FOOT))):\n",
    "        return 2\n",
    "\n",
    "    #chase inside 84in to 6in, -20in to 20in horizontal, (strike zone * 200%)\n",
    "    return 3\n",
    "\n",
    "\n",
    "#preprocessing function used to generate a single number that will be used to classify the ball/strike count before the current pitch \n",
    "#returns int [0 - 11]\n",
    "def PitchCount(balls, strikes):\n",
    "    # Strikes: 0  1   2\n",
    "    # Balls v|---------- \n",
    "    #       0| 0  1   2 \n",
    "    #       1| 3  4   5\n",
    "    #       2| 6  7   8\n",
    "    #       3| 9  10  11\n",
    "    if(balls == 0):\n",
    "        if(strikes == 0):\n",
    "            return 0\n",
    "        if (strikes == 1):\n",
    "            return 1\n",
    "        return 2\n",
    "    if(balls == 1):\n",
    "        if(strikes == 0):\n",
    "            return 3\n",
    "        if (strikes == 1):\n",
    "            return 4\n",
    "        return 5\n",
    "    if(balls == 2):\n",
    "        if(strikes == 0):\n",
    "            return 6\n",
    "        if (strikes == 1):\n",
    "            return 7\n",
    "        return 8\n",
    "    if(balls == 3):\n",
    "        if(strikes == 0):\n",
    "            return 9\n",
    "        if (strikes == 1):\n",
    "            return 10\n",
    "        return 11\n",
    "\n",
    "\n",
    "#preprocessing function generates the ground truth hitability of a pitch\n",
    "#these values will definitely need to be adjusted\n",
    "def GenerateGroundTruthLabels(pitchCall):\n",
    "    if pitchCall == 'BallCalled':\n",
    "        return 0\n",
    "    if pitchCall == 'BallIntentional' or pitchCall == 'HitByPitch':\n",
    "        return 1\n",
    "    if pitchCall == 'StrikeSwinging' or pitchCall == 'StrikeCalled':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def GetSubCategory(data, feature, key):\n",
    "    #determine the rows to be dropped\n",
    "    sub_data = data.loc[data[feature] == key]\n",
    "    return sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import time\n",
    "\n",
    "#scikit learn doesnt support categorical columns\n",
    "def TrainValidateTree(training_data, validation_data, possible_min_leaf_samples=None, possible_depths=None):\n",
    "    X = training_data.loc[:,~training_data.columns.isin(LABELS_FEATURE)]\n",
    "    y = training_data.loc[:,training_data.columns == LABELS_FEATURE[0]]\n",
    "\n",
    "    vX = validation_data.loc[:,~validation_data.columns.isin(LABELS_FEATURE)]\n",
    "    vy = validation_data.loc[:,validation_data.columns == LABELS_FEATURE[0]]\n",
    "\n",
    "    #validation (hyper-parameter tuning)\n",
    "    parameter_accuracy = []\n",
    "    for msl in possible_min_leaf_samples:\n",
    "        for d in possible_depths:\n",
    "            #train on training with this iteration of parameters\n",
    "            decision_tree = tree.DecisionTreeClassifier(min_samples_leaf=msl, max_depth=d)\n",
    "            begin_time = time.time()\n",
    "            decision_tree = decision_tree.fit(X, y)\n",
    "            train_time = time.time() - begin_time\n",
    "            #then check accuracy of validation data\n",
    "            begin_time = time.time()\n",
    "            val_pred = decision_tree.predict(vX)\n",
    "            val_time = time.time() - begin_time\n",
    "            score = metrics.accuracy_score(vy,val_pred)\n",
    "            #put parameters and accuracy in matrix\n",
    "            tree_metrics = msl,d,score,decision_tree.tree_.node_count,train_time,val_time\n",
    "\n",
    "            parameter_accuracy.append(tree_metrics)\n",
    "            print(tree_metrics)\n",
    "\n",
    "    #select parameters with highest accuracy\n",
    "    parameter_accuracy.sort(key = lambda x:x[2])\n",
    "\n",
    "    best_parameters = parameter_accuracy[-1]\n",
    "    print(best_parameters)\n",
    "\n",
    "    #train new decision tree using best hyperparameters found above\n",
    "    best_decision_tree = tree.DecisionTreeClassifier(min_samples_leaf=best_parameters[0], max_depth=best_parameters[1])\n",
    "    begin_time = time.time()\n",
    "    best_decision_tree = decision_tree.fit(X, y)\n",
    "    train_time = time.time() - begin_time\n",
    "\n",
    "    begin_time = time.time()\n",
    "    res_pred = best_decision_tree.predict(vX)\n",
    "    val_time = time.time() - begin_time\n",
    "    score = metrics.accuracy_score(vy,res_pred)\n",
    "    print(score*100)\n",
    "\n",
    "    return best_decision_tree, best_parameters[0], best_parameters[1], train_time, val_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "import time\n",
    "\n",
    "#use this cell to find the optimal hyperparameters for the model\n",
    "def TrainValidateForest(training_data, validation_data, jobs=-1, subtrees=[100], depths=[None], \\\n",
    "                        min_sample_split=[2], min_samples_leaf=[1], max_features=['auto'], max_leaf_nodes=[None]):\n",
    "\n",
    "    X = training_data.loc[:,~training_data.columns.isin(LABELS_FEATURE)]\n",
    "    y = training_data.loc[:,training_data.columns == LABELS_FEATURE[0]]\n",
    "\n",
    "    vX = validation_data.loc[:,~validation_data.columns.isin(LABELS_FEATURE)]\n",
    "    vy = validation_data.loc[:,validation_data.columns == LABELS_FEATURE[0]]\n",
    "\n",
    "    parameter_accuracy = []\n",
    "    for n_trees in subtrees:\n",
    "        for d in depths:\n",
    "            for mss in min_sample_split:\n",
    "                for msl in min_samples_leaf:\n",
    "                    for mf in max_features:\n",
    "                        for mln in max_leaf_nodes:\n",
    "                            #train on training with this iteration of parameters\n",
    "                            decision_forest = ensemble.RandomForestClassifier(n_estimators=n_trees, max_depth=d, \\\n",
    "                                min_samples_split=mss, min_samples_leaf=msl, max_features=mf, max_leaf_nodes=mln, n_jobs=jobs)\n",
    "\n",
    "                            begin_time = time.time()\n",
    "                            decision_forest = decision_forest.fit(X, y.values.ravel())\n",
    "                            train_time = time.time() - begin_time\n",
    "\n",
    "                            #then check accuracy of validation data\n",
    "                            begin_time = time.time()\n",
    "                            val_pred = decision_forest.predict(vX)\n",
    "                            val_time = time.time() - begin_time\n",
    "\n",
    "                            score = metrics.accuracy_score(vy,val_pred)\n",
    "\n",
    "                            #put parameters and accuracy in matrix\n",
    "                            tree_metrics = score,n_trees,d,mss,msl,mf,mln,train_time,val_time\n",
    "                            parameter_accuracy.append(tree_metrics)\n",
    "                            print(tree_metrics)\n",
    "\n",
    "    #select parameters with highest accuracy\n",
    "    parameter_accuracy.sort(key = lambda x:x[0])\n",
    "\n",
    "    best_parameters = parameter_accuracy[-1]\n",
    "    print(best_parameters)\n",
    "\n",
    "    #train new decision tree using best hyperparameters found above\n",
    "    best_decision_forest = ensemble.RandomForestClassifier(n_estimators=best_parameters[1], max_depth=best_parameters[2], min_samples_split=best_parameters[3], min_samples_leaf=best_parameters[4], max_features=best_parameters[5], max_leaf_nodes=best_parameters[6], n_jobs=jobs)\n",
    "\n",
    "    begin_time = time.time()\n",
    "    best_decision_forest = decision_forest.fit(X, y.values.ravel())\n",
    "    train_time = time.time() - begin_time\n",
    "\n",
    "    begin_time = time.time()\n",
    "    res_pred = best_decision_forest.predict(vX)\n",
    "    val_time = time.time() - begin_time\n",
    "\n",
    "    score = metrics.accuracy_score(vy,res_pred)\n",
    "    print(score*100)\n",
    "\n",
    "    return best_decision_forest, score, best_parameters[1], best_parameters[2], best_parameters[3], best_parameters[4], best_parameters[5], best_parameters[6], train_time, val_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use graphviz to make pdf and image of tree\n",
    "import graphviz\n",
    "\n",
    "def plot_tree(decision_tree, feature_labels=TRAINING_FEATURES, name=\"bball_basic_decision_tree_labeled\", folder_name=None):\n",
    "    print(decision_tree.tree_.node_count)\n",
    "\n",
    "    class_labels = ['BallCalled','BallIntentional/HitByPitch','StrikeSwinging/StrikeCalled',\"Correct Swing\"]\n",
    "\n",
    "    if folder_name is None:\n",
    "    #tree with recognizable labels and color coded nodes corresponding to classes\n",
    "        dot_data = tree.export_graphviz(decision_tree, out_file=None,\n",
    "                                        feature_names = feature_labels,\n",
    "                                        class_names = class_labels,\n",
    "                                        filled=True, rounded = True,\n",
    "                                        special_characters=True)\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        graph.render(filename=name, cleanup=True, format='png', directory=\"tree_plots\")\n",
    "    \n",
    "    else:\n",
    "        dot_data = tree.export_graphviz(decision_tree, out_file=None,\n",
    "                                        feature_names = feature_labels,\n",
    "                                        class_names = class_labels,\n",
    "                                        filled=True, rounded = True,\n",
    "                                        special_characters=True)\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        graph.render(filename=name, cleanup=True, format='png', directory=\"tree_plots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fastball\n",
      "total samples: 580335 \n",
      "training samples: 348201 \n",
      "validation samples: 232134 \n",
      "sum of training, and validation: 580335\n",
      "Curveball\n",
      "total samples: 85542 \n",
      "training samples: 51325 \n",
      "validation samples: 34217 \n",
      "sum of training, and validation: 85542\n",
      "ChangeUp\n",
      "total samples: 109613 \n",
      "training samples: 65767 \n",
      "validation samples: 43846 \n",
      "sum of training, and validation: 109613\n",
      "Slider\n",
      "total samples: 176522 \n",
      "training samples: 105913 \n",
      "validation samples: 70609 \n",
      "sum of training, and validation: 176522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lancekevin/opt/miniconda3/envs/MLSclass/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/Users/lancekevin/opt/miniconda3/envs/MLSclass/lib/python3.9/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#import the columns we will need for training and preprocessing\n",
    "bball_data = pd.read_csv(data_folder+bball_data_2_file, usecols=['Pitcher', 'PitcherThrows', 'Batter', 'BatterSide', 'PitchCall', 'RunsScored', 'VertBreak', 'HorzBreak', 'ZoneSpeed', 'VertApprAngle', 'HorzApprAngle', 'ZoneTime', 'PlateLocHeight', 'PlateLocSide', 'Balls', 'Strikes', 'TaggedPitchType'])\n",
    "\n",
    "#run preprocessing functions and normalize data\n",
    "bball_data['BallStrikeNum'] = bball_data.apply(lambda pitch : PitchCount(pitch['Balls'], pitch['Strikes']), axis=1)\n",
    "bball_data['GroundTruth'] = bball_data.apply(lambda pitch : GenerateGroundTruthLabels(pitch['PitchCall']), axis=1)\n",
    "#bball_data['norm_PlateLocHeight'] = bball_data.apply(lambda pitch : normalize_PlateLocHeight(pitch['PlateLocHeight']), axis=1)\n",
    "bball_data['Zone'] = bball_data.apply(lambda pitch : PlateZone(pitch['PlateLocHeight'], pitch['PlateLocSide']), axis=1)\n",
    "\n",
    "#drop all features used for preprocessing\n",
    "bball_data.drop(labels=PREPROCESSING_KEYS, axis=1, inplace=True)\n",
    "\n",
    "#get data will all [key] as value for [feature]\n",
    "#bball_data=GetSubCategory(data=bball_data,feature='TaggedPitchType',key='Fastball')\n",
    "\n",
    "#Remove NaN valued rows\n",
    "bball_data.dropna(inplace=True)\n",
    "bball_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rows_by_key = []\n",
    "for curr_key in TaggedPitchType_Keys:\n",
    "        rows_by_key.append(GetSubCategory(data=bball_data,feature='TaggedPitchType',key=curr_key))\n",
    "\n",
    "split_data = []\n",
    "for i in range(len(rows_by_key)):\n",
    "        #drop all colums that cointain strings\n",
    "        curr_data = rows_by_key[i]\n",
    "        curr_data.drop(labels=SUBCATEGORY_KEYS, axis = 1, inplace = True)\n",
    "        curr_data.dropna(inplace=True)\n",
    "        curr_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        print(TaggedPitchType_Keys[i])\n",
    "        this_keyset = []\n",
    "\n",
    "        #splitting data into training, validation, testing\n",
    "        total_samples = len(curr_data.index)\n",
    "        training_samples = math.floor(PCT_FOR_TRAIN*total_samples)\n",
    "        validation_samples = math.ceil((1-PCT_FOR_TRAIN)*total_samples)\n",
    "\n",
    "        this_keyset.append(total_samples)\n",
    "        this_keyset.append(training_samples)\n",
    "        this_keyset.append(validation_samples)\n",
    "\n",
    "        sum = training_samples+validation_samples\n",
    "\n",
    "        print(\"total samples:\",total_samples,\n",
    "                \"\\ntraining samples:\",training_samples,\n",
    "                \"\\nvalidation samples:\",validation_samples,\n",
    "                \"\\nsum of training, and validation:\",sum)\n",
    "\n",
    "        #makes shuffled version of the data\n",
    "        indices = np.arange(total_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        shuffled_bball_data = curr_data.reindex(indices).reset_index(drop=True)\n",
    "\n",
    "        #gets the amount of random data points as determined by set proportion\n",
    "        training_data = shuffled_bball_data.iloc[0:training_samples]\n",
    "        validation_data = shuffled_bball_data.iloc[training_samples:training_samples+validation_samples]\n",
    "\n",
    "        this_keyset.append(training_data)\n",
    "        this_keyset.append(validation_data)\n",
    "\n",
    "        split_data.append(this_keyset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = [8, 14]\n",
    "#mls = [1000]\n",
    "\n",
    "#best_hyperparams_and_model = TrainValidateTree(training_data = training_data, validation_data = validation_data, possible_min_leaf_samples=mls, possible_depths=d)\n",
    "#plot_tree(best_hyperparams_and_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6502321934744587, 100, None, 100, 50, 1, None, 13.762155055999756, 0.7470080852508545)\n",
      "(0.6614800072371992, 100, None, 100, 50, 3, None, 28.470919132232666, 0.8792951107025146)\n",
      "(0.6613938501038193, 100, None, 100, 50, 9, None, 69.62489604949951, 0.7145979404449463)\n",
      "(0.6614800072371992, 100, None, 100, 50, 3, None, 28.470919132232666, 0.8792951107025146)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pr/bpwqt_fn7jq48s08_cz264nw0000gn/T/ipykernel_59673/2634575240.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mvd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     best_hyperparams.append(TrainValidateForest(training_data=td, validation_data=vd, subtrees=n_trees, depths=d, \\\n\u001b[0m\u001b[1;32m     23\u001b[0m                         min_sample_split=mss, min_samples_leaf=msl, max_features=mf, max_leaf_nodes=mln))\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pr/bpwqt_fn7jq48s08_cz264nw0000gn/T/ipykernel_59673/389432837.py\u001b[0m in \u001b[0;36mTrainValidateForest\u001b[0;34m(training_data, validation_data, jobs, subtrees, depths, min_sample_split, min_samples_leaf, max_features, max_leaf_nodes)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mbegin_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mbest_decision_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbegin_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/MLSclass/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/MLSclass/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/MLSclass/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/MLSclass/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/MLSclass/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/MLSclass/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/MLSclass/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_trees = [100]\n",
    "d = [None]\n",
    "mss = [100]\n",
    "msl = [100]\n",
    "mf = [len(TRAINING_FEATURES)]\n",
    "mln = [None]\n",
    "\n",
    "#n_trees = list(n_trees[0])\n",
    "#d = list(d[0])\n",
    "#mss = list(mss[0])\n",
    "#msl = list(msl[0])\n",
    "#mf = list(mf[0])\n",
    "#mln = list(mln[0])\n",
    "\n",
    "model_list = []\n",
    "\n",
    "for subfeature_idx in range(len(split_data)):\n",
    "    curr_row = split_data[subfeature_idx]\n",
    "\n",
    "    td = curr_row[3]\n",
    "    vd = curr_row[4]\n",
    "    model_list.append(TrainValidateForest(training_data=td, validation_data=vd, subtrees=n_trees, depths=d, \\\n",
    "                        min_sample_split=mss, min_samples_leaf=msl, max_features=mf, max_leaf_nodes=mln))\n",
    "\n",
    "#i = 0\n",
    "#for tree_ in model_list[0].estimators_:\n",
    "#    plot_tree(decision_tree=tree_, name='forest_tree'+str(i))\n",
    "#    i += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09b85b2302065c94dd0f4da7a9ce6616ad9edf4bd58771fbf5710515810e6204"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('csce585': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
