{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_folder = \"./data/\"\n",
    "\n",
    "#Get and load data\n",
    "# pitch_14_17_file = \"pitcher_2014_2017.csv\"\n",
    "bball_data_2_file = \"Baseball Data-2.csv\"\n",
    "\n",
    "TRAINING_FEATURES = ['RunsScored', 'VertBreak', 'HorzBreak', 'PlateLocSide', 'ZoneSpeed',\n",
    "       'VertApprAngle', 'HorzApprAngle', 'ZoneTime', 'BallStrikeNum', 'norm_PlateLocHeight']\n",
    "       \n",
    "LABELS_FEATURE = ['GroundTruth']\n",
    "SUBCATEGORY_KEYS = ['Pitcher', 'Batter', 'PitcherThrows', 'BatterSide', 'TaggedPitchType']\n",
    "PREPROCESSING_KEYS = ['Balls', 'Strikes', 'PitchCall', 'PlateLocHeight']\n",
    "\n",
    "PCT_FOR_TRAIN = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing function which moves 0 of PlateLocHeight to center of strike zone from ground\n",
    "#returns a value 2.5ft (30in) less than the original value\n",
    "def normalize_PlateLocHeight(PlateLocHeight):\n",
    "    return ((PlateLocHeight * 12) - 30)/12\n",
    "\n",
    "\n",
    "#preprocessing function used to calculate the plate location (this will be different than PitchCall (even in terms of BallCalled vs StrikeCalled))\n",
    "#returns classification: heart (strike) = 0, shadow (strike) = 1, shadow (ball) = 2, chase (ball) = 3, waste (ball) = 4\n",
    "def PlateZone(PlateLocHeight, PlateLocSide):\n",
    "    FOOT = 12\n",
    "\n",
    "    #waste zone\n",
    "    #outside 84in to 6in, -20in to 20in horizontal, (strike zone * 200%)\n",
    "    if ((PlateLocHeight > 7 or PlateLocHeight < 0.5) and (PlateLocSide < -(20/FOOT) or PlateLocSide > (20/FOOT))):\n",
    "        return 4\n",
    "\n",
    "    #heart zone\n",
    "    #inside 38in to 22in vertical, -6.7in to 6.7in horizontal, (strike zone size * 67%)\n",
    "    if ((PlateLocHeight < (38/FOOT) and PlateLocHeight > (22/FOOT)) and (PlateLocSide > (-6.7/FOOT) and PlateLocSide < (6.7/FOOT))):\n",
    "        return 0\n",
    "\n",
    "    #strike zone \n",
    "    #inside 42in to 18in vertical, -10in to 10in horizontal\n",
    "    if (PlateLocHeight < (42/FOOT) and PlateLocHeight > (18/FOOT) and (PlateLocSide > (-10/FOOT) and PlateLocSide < (10/FOOT))):\n",
    "        return 1\n",
    "\n",
    "    #shadow zone\n",
    "    #inside 46in to 14in vertical, -13.3in to 13.3in horizontal, (strike zone size * 133%)\n",
    "    if (PlateLocHeight < (46/FOOT) and PlateLocHeight > (14/FOOT) and (PlateLocSide > (-13.3/FOOT) and PlateLocSide < (13.3/FOOT))):\n",
    "        return 2\n",
    "\n",
    "    #chase inside 84in to 6in, -20in to 20in horizontal, (strike zone * 200%)\n",
    "    return 3\n",
    "\n",
    "\n",
    "#preprocessing function used to generate a single number that will be used to classify the ball/strike count before the current pitch \n",
    "#returns int [0 - 11]\n",
    "def PitchCount(balls, strikes):\n",
    "    # Strikes: 0  1   2\n",
    "    # Balls v|---------- \n",
    "    #       0| 0  1   2 \n",
    "    #       1| 3  4   5\n",
    "    #       2| 6  7   8\n",
    "    #       3| 9  10  11\n",
    "    if(balls == 0):\n",
    "        if(strikes == 0):\n",
    "            return 0\n",
    "        if (strikes == 1):\n",
    "            return 1\n",
    "        return 2\n",
    "    if(balls == 1):\n",
    "        if(strikes == 0):\n",
    "            return 3\n",
    "        if (strikes == 1):\n",
    "            return 4\n",
    "        return 5\n",
    "    if(balls == 2):\n",
    "        if(strikes == 0):\n",
    "            return 6\n",
    "        if (strikes == 1):\n",
    "            return 7\n",
    "        return 8\n",
    "    if(balls == 3):\n",
    "        if(strikes == 0):\n",
    "            return 9\n",
    "        if (strikes == 1):\n",
    "            return 10\n",
    "        return 11\n",
    "\n",
    "\n",
    "#preprocessing function generates the ground truth hitability of a pitch\n",
    "#these values will definitely need to be adjusted\n",
    "def GenerateGroundTruthLabels(pitchCall):\n",
    "    if pitchCall == 'BallCalled':\n",
    "        return 0\n",
    "    if pitchCall == 'BallIntentional' or pitchCall == 'HitByPitch':\n",
    "        return 1\n",
    "    if pitchCall == 'StrikeSwinging' or pitchCall == 'StrikeCalled':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def GetSubCategory(data=None,feature=None, key=None):\n",
    "    if data is None or feature is None or key is None:\n",
    "        print(\"feature and key are required parameters, data is optional\")\n",
    "        return None\n",
    "    \n",
    "    #determine the rows to be dropped\n",
    "    sub_data = data.loc[data[feature] == key]\n",
    "    return sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 1029479 \n",
      "training samples: 720635 \n",
      "validation samples: 308844 \n",
      "sum of training, and validation: 1029479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['RunsScored', 'VertBreak', 'HorzBreak', 'PlateLocSide', 'ZoneSpeed',\n",
       "       'VertApprAngle', 'HorzApprAngle', 'ZoneTime', 'BallStrikeNum',\n",
       "       'GroundTruth', 'norm_PlateLocHeight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the columns we will need for training and preprocessing\n",
    "bball_data = pd.read_csv(data_folder+bball_data_2_file, usecols=['Pitcher', 'PitcherThrows', 'Batter', 'BatterSide', 'PitchCall', 'RunsScored', 'VertBreak', 'HorzBreak', 'ZoneSpeed', 'VertApprAngle', 'HorzApprAngle', 'ZoneTime', 'PlateLocHeight', 'PlateLocSide', 'Balls', 'Strikes', 'TaggedPitchType'])\n",
    "\n",
    "#run preprocessing functions and normalize data\n",
    "bball_data['BallStrikeNum'] = bball_data.apply(lambda pitch : PitchCount(pitch['Balls'], pitch['Strikes']), axis=1)\n",
    "bball_data['GroundTruth'] = bball_data.apply(lambda pitch : GenerateGroundTruthLabels(pitch['PitchCall']), axis=1)\n",
    "bball_data['norm_PlateLocHeight'] = bball_data.apply(lambda pitch : normalize_PlateLocHeight(pitch['PlateLocHeight']), axis=1)\n",
    "#bball_data['Zone'] = bball_data.apply(lambda pitch : PlateZone(pitch['PlateLocHeight'], pitch['PlateLocSide']))\n",
    "\n",
    "#drop all features used for preprocessing\n",
    "bball_data.drop(labels=PREPROCESSING_KEYS, axis=1, inplace=True)\n",
    "\n",
    "#Remove NaN valued rows\n",
    "bball_data.dropna(inplace=True)\n",
    "bball_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#get data will all [key] as value for [feature]\n",
    "#bball_data=GetSubCategory(data=baseball_data,feature=,key=)\n",
    "\n",
    "#drop all features that could be useful subcategories\n",
    "bball_data.drop(labels=SUBCATEGORY_KEYS, axis = 1, inplace=True)\n",
    "\n",
    "#splitting data into training, validation, testing\n",
    "total_samples = len(bball_data.index)\n",
    "training_samples = math.floor(PCT_FOR_TRAIN*total_samples)\n",
    "validation_samples = math.ceil((1-PCT_FOR_TRAIN)*total_samples)\n",
    "\n",
    "sum = training_samples+validation_samples\n",
    "\n",
    "print(\"total samples:\",total_samples,\n",
    "        \"\\ntraining samples:\",training_samples,\n",
    "        \"\\nvalidation samples:\",validation_samples,\n",
    "        \"\\nsum of training, and validation:\",sum)\n",
    "\n",
    "#makes shuffled version of the data\n",
    "indices = np.arange(total_samples)\n",
    "np.random.shuffle(indices)\n",
    "shuffled_bball_data = bball_data.reindex(indices).reset_index(drop=True)\n",
    "\n",
    "#gets the amount of random data points as determined by set proportion\n",
    "training_data = shuffled_bball_data.iloc[0:training_samples]\n",
    "validation_data = shuffled_bball_data.iloc[training_samples:training_samples+validation_samples]\n",
    "\n",
    "training_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "#scikit learn doesnt support categorical columns\n",
    "def TrainValidateTree(training_data, validation_data, possible_min_leaf_samples=None, possible_depths=None):\n",
    "    X = training_data.loc[:,~training_data.columns.isin(LABELS_FEATURE)]\n",
    "    y = training_data.loc[:,training_data.columns == LABELS_FEATURE[0]]\n",
    "\n",
    "    vX = validation_data.loc[:,~validation_data.columns.isin(LABELS_FEATURE)]\n",
    "    vy = validation_data.loc[:,validation_data.columns == LABELS_FEATURE[0]]\n",
    "\n",
    "    #validation (hyper-parameter tuning)\n",
    "    parameter_accuracy = []\n",
    "    for msl in possible_min_leaf_samples:\n",
    "        for d in possible_depths:\n",
    "            #train on training with this iteration of parameters\n",
    "            decision_tree = tree.DecisionTreeClassifier(min_samples_leaf=msl, max_depth=d)\n",
    "            decision_tree = decision_tree.fit(X, y)\n",
    "            #then check accuracy of validation data\n",
    "            val_pred = decision_tree.predict(vX)\n",
    "            score = metrics.accuracy_score(vy,val_pred)\n",
    "            #put parameters and accuracy in matrix\n",
    "            parameter_accuracy.append((msl,d,score,decision_tree.tree_.node_count))\n",
    "            print(msl,d,score,decision_tree.tree_.node_count)\n",
    "\n",
    "    #select parameters with highest accuracy\n",
    "    parameter_accuracy.sort(key = lambda x:x[2])\n",
    "\n",
    "    best_parameters = parameter_accuracy[-1]\n",
    "    print(best_parameters)\n",
    "\n",
    "    #train new decision tree using best hyperparameters found above\n",
    "    best_decision_tree = tree.DecisionTreeClassifier(min_samples_leaf=best_parameters[0], max_depth=best_parameters[1])\n",
    "    best_decision_tree = decision_tree.fit(X, y)\n",
    "\n",
    "    res_pred = best_decision_tree.predict(vX)\n",
    "    score = metrics.accuracy_score(vy,res_pred)\n",
    "    print(score*100)\n",
    "\n",
    "    return best_decision_tree, best_parameters[0], best_parameters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use graphviz to make pdf and image of tree\n",
    "import graphviz\n",
    "\n",
    "def plot_tree(decision_tree, feature_labels=TRAINING_FEATURES):\n",
    "    print(decision_tree.tree_.node_count)\n",
    "\n",
    "    class_labels = ['BallCalled','BallIntentional/HitByPitch','StrikeSwinging/StrikeCalled',\"Correct Swing\"]\n",
    "\n",
    "    #tree with recognizable labels and color coded nodes corresponding to classes\n",
    "    dot_data = tree.export_graphviz(decision_tree, out_file=None,\n",
    "                                    feature_names = feature_labels,\n",
    "                                    class_names = class_labels,\n",
    "                                    filled=True, rounded = True,\n",
    "                                    special_characters=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render(\"bball_basic_decision_tree_labeled\")\n",
    "    graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RunsScored', 'VertBreak', 'HorzBreak', 'PlateLocSide', 'ZoneSpeed',\n",
      "       'VertApprAngle', 'HorzApprAngle', 'ZoneTime', 'BallStrikeNum',\n",
      "       'norm_PlateLocHeight'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pr/bpwqt_fn7jq48s08_cz264nw0000gn/T/ipykernel_77453/1956490358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbest_hyperparams_and_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainValidateTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible_min_leaf_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible_depths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hyperparams_and_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAINING_FEATURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pr/bpwqt_fn7jq48s08_cz264nw0000gn/T/ipykernel_77453/2785534565.py\u001b[0m in \u001b[0;36mTrainValidateTree\u001b[0;34m(training_data, validation_data, possible_min_leaf_samples, possible_depths)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m#train on training with this iteration of parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mdecision_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mdecision_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m#then check accuracy of validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/MLSclass/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/MLSclass/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d = [8, 12, 14]\n",
    "mls = [1000, 3000, 5000]\n",
    "\n",
    "\n",
    "best_hyperparams_and_model = TrainValidateTree(training_data = training_data, validation_data = validation_data, possible_min_leaf_samples=mls, possible_depths=d)\n",
    "plot_tree(best_hyperparams_and_model[0], feature_labels=TRAINING_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "#use this cell to find the optimal hyperparameters for the model\n",
    "def TrainValidateForest(training_data, validation_data, possible_subtrees=None, possible_min_leaf_samples=None, possible_depths=None):\n",
    "    X = training_data.loc[:,~training_data.columns.isin(LABELS_FEATURE)]\n",
    "    y = training_data.loc[:,training_data.columns == LABELS_FEATURE[0]]\n",
    "\n",
    "    vX = validation_data.loc[:,~validation_data.columns.isin(LABELS_FEATURE)]\n",
    "    vy = validation_data.loc[:,validation_data.columns == LABELS_FEATURE[0]]\n",
    "\n",
    "    parameter_accuracy = []\n",
    "    for msl in possible_min_leaf_samples:\n",
    "        for d in possible_depths:\n",
    "            for n_trees in possible_subtrees:\n",
    "                #train on training with this iteration of parameters\n",
    "                decision_forest = ensemble.RandomForestClassifier(n_estimators=n_trees, min_samples_leaf=msl, max_depth=d)\n",
    "                decision_forest = decision_forest.fit(X, y.values.ravel())\n",
    "                #then check accuracy of validation data\n",
    "                val_pred = decision_forest.predict(vX)\n",
    "                score = metrics.accuracy_score(vy,val_pred)\n",
    "                #put parameters and accuracy in matrix\n",
    "                parameter_accuracy.append((msl,d,n_trees,score))\n",
    "                print(msl,d,n_trees,score)\n",
    "\n",
    "    #select parameters with highest accuracy\n",
    "    parameter_accuracy.sort(key = lambda x:x[3])\n",
    "\n",
    "    best_parameters = parameter_accuracy[-1]\n",
    "    print(best_parameters)\n",
    "\n",
    "    #train new decision tree using best hyperparameters found above\n",
    "    best_decision_forest = ensemble.RandomForestClassifier(min_samples_leaf=best_parameters[0], max_depth=best_parameters[1], n_estimators=best_parameters[2])\n",
    "    best_decision_forest = decision_forest.fit(X, y.values.ravel())\n",
    "\n",
    "    res_pred = best_decision_forest.predict(vX)\n",
    "    score = metrics.accuracy_score(vy,res_pred)\n",
    "    print(score*100)\n",
    "\n",
    "    return best_decision_forest, best_parameters[0], best_parameters[1], best_parameters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [50, 100, 200, 300]\n",
    "d = [8, 10, 12, 14]\n",
    "mls = [1000, 3000, 5000]\n",
    "best_hyperparams = TrainValidateForest(training_data=training_data,validation_data=validation_data,possible_subtrees=n_trees, possible_depths=d, possible_min_leaf_samples=mls)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09b85b2302065c94dd0f4da7a9ce6616ad9edf4bd58771fbf5710515810e6204"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('csce585': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
